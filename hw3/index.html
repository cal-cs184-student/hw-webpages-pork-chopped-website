<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
/*AI helped generate table style*/
            table {
                border-collapse: collapse;
                margin-bottom: 20px;
            }

            table, th, td {
                border: 1px solid #333;
            }

            th, td {
                padding: 8px 12px;
                text-align: center;
            }

            h2 {
                margin-bottom: 5px;
            }
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
			<div style="text-align: center;">Names: Patrick Sanchez, Karson Du </div>

			<br>

			Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-pork-chopped-website/hw3/index.html">Webpage</a>

			<br>

			Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-pork3">Repo</a>

			<figure>
				<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%" />
				<figcaption>Geeked vs Locked in</figcaption>
			</figure>

			<!--
	We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
	-->

			<h2>Overview</h2>

			The many things we implemented in this assignment was first Ray Generation and Scene Intersection which is the basics of rendering since our rays are the actual items doing the traversals to render items. Next we implemented Bounding Volume Hierachy (BVH) which allowed for quicker checking of intersections allowing us to render images faster. Next, we implemented direct lighting which allowed us to render images using zero-bounce illumination and direct lighting using uniform-hemisphere sampling. Then, we implemented global illumination which helped render images using N boucnes of light as well as Russian Roulette to cut off some rays early. Finally, we implemented adaptive sampling which takes advantage of the fact some pixels converge faster than others and some pixels need more samples to get rid of noise. One of the interesting things we've leanred was how much adaptive sampling can improve the look of images compared to increasing the pure amount of samples, focusing less on pixels that converge faster and more on pixels that take longer to converge, we end up with images that look much nicer with less noise than just increasing the amount of samples.

			<h2>Part 1: Ray Generation and Scene Intersection</h2>
			<p>* Task 1.1: Ray generation is a fundamental piece of intersection-based light algorithms. Given a normalized (x,y) in image space [0,0]:[1,1] that we would like convert into world space, we first convert from image space to camera space defaulted to facing the z-axis [-tan(0.5*hFov),-tan(0.5*vFov),-1]:[tan(0.5*hFov),tan(0.5*vFov),-1]. This is processed by re-centering the origin in image space before converting the hFov and vFov into radians and calculating the camera space coordinates. From there, we apply the camera to world rotation matrix to convert into the world space. Finally, we normalize the ray direction in world space, and return a ray starting at the camera's position in world space, and with generic nClip and fClip boundaries for time.</p>
			<p>* Task 1.2: We also had to implement generation of pixel samples. We initialized a "bucket" to later collect radiance values. For the desired number of samples, we generate a sample by adding a unit sample of a 1x1 pixel on top of the (x,y) coordinate, and then add our estimated radiance to our bucket. After looping is complete, we average down and update our sampleBuffer to reflect the expected pixel global illumination radiance.</p>
			<p>* Task 1.3 + 1.4: Now with rays prepared, we could implement the first intersection algorithm. In the triangle-ray intersection case, we have two functions to check if there's an intersection, and another to update the relevant intersection structure if so. However, the two are practically the same, minus the updates in the former, so the overall approach follows this process: Following the <b>Moller Trumbore</b> Alorithm from lecture, we could more efficiently calculate the barycentric coordinates of an intersection point within the triangle! Essentially, the formulae have you take the triangle's points and the ray, define the edges of the triangle, shift the ray's origin to the first point, and then use cross-products to determine scaling factors for the barycentric coordinates. we then normalize the time of intersection, and two of the barycentric coordinates, by dividing by the determinant. Afterwards, we use the determinant and calculated b1 and b2 coordinate values to check the intersection is valid (not through an edge or out of time bounds). We can then update the intersection structure accordingly! After triangles, we added sphere-intersection via its own specific formulae from lecture.</p>
			<p>Here are some images rendered with normal shading.</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="P1.1.png" width="400px" />
							<figcaption>An empty room of made of triangles.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="P1.2.png" width="400px" />
							<figcaption>The same room but now with two spheres.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="P1.3.png" width="400px" />
							<figcaption>A banana mesh on a pedastal.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="P1.4.png" width="400px" />
							<figcaption>A cute cow figure.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<h2>Part 2: Bounding Volume Hierarchy</h2>
			<p>Bounding Volume Hierarchies are a recursive method to split a mesh into successively small but efficiently rendered boxes. Instead of calculating every ray, we can determine whether the ray intersects a general box around the mesh, and if that doesn't short circuit, check if the primitives are within reasonable time frames based on previous intersections and ray positions. We constructed our BVH by adding primitives to an overall bounding box, and then working down we define the split points of inner bounding volumes by the "widest" axis based on each axis's extent (difference between max and min points) We then used AI to help us code an iterative splitter of all the primitives into their respective partitions on either side of the split point. We then successively continue to construct further "left" and "right" inner bounding volumes on the two sides we just split.</p>
			<p>We then used the ray-plane intersection algorithm from lecture to determine when input rays would intersect the x, y, and z axes of a bounding box, and update the most restrictive time values (tightest bounds of all axes combined) if there is a valid intersection.</p>
			<p>Finally, we could short circuit if we notice there are no valid intersections with the bounding box. Otherwise, if the node is a leaf, we can iterate through the primitives (like triangles) to individually calculate their ray intersections; if the node is a parent then we check if the children nodes contain valid intersections, until we reach the leaf case (or until it short circuits).</p>
			<p>The heuristic we chose, going off the widest extents of each axis, felt like a good compromise between familiarity and efficiency. In the case where splitting by the widest extent along the split point does not return two partitions, we fall back on a median split as a failsafe to infinite loops. The widest extent approach mimics the median line, but incorporates some context from the bounding box to make what is likely a good estimator of a balanced split between primitives, without having to calculate average centroid positions or surface areas (although these are other approaches valid from lecture).</p>
			<p>Here are some complex meshes and comparisons of how their renders perform with and without BVH acceleration on a single-threaded i7-12700H with 480000 rays tested.</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="cow_screenshot_3-22_14-16-0.png" width="400px" />
							<figcaption>Relatively low complexity cow - 5856 primitives.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="building_screenshot_3-22_12-52-51.png" width="400px" />
							<figcaption>First complex model, a building - 39506 primitives.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="maxplanck_screenshot_3-22_12-51-51.png" width="400px" />
							<figcaption>A bust of Max Planck - 50801 primitives.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="dragon_screenshot_3-22_12-50-41.png" width="400px" />
							<figcaption>A frightening dragon - 105120 primitives.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="CBlucy_screenshot_3-22_12-52-29.png" width="400px" />
							<figcaption>A devastating render of Lucy - 133796 primitives!</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<!--Tables AI generated based off of collected data, tables get their own element type before headers and data are declared-->
			<!-- Render Time Table -->
			<h2>Total Render Time</h2>
			<table>
				<tr>
					<th>Filenames</th>
					<th>Time w/ BVH (sec)</th>
					<th>Time w/out BVH (sec)</th>
				</tr>
				<tr>
					<td>Cow</td>
					<td>0.1489</td>
					<td>28.2115</td>
				</tr>
				<tr>
					<td>Building</td>
					<td>0.1202</td>
					<td>213.7916</td>
				</tr>
				<tr>
					<td>MaxPlanck</td>
					<td>0.2291</td>
					<td>390.0616</td>
				</tr>
				<tr>
					<td>Dragon</td>
					<td>0.2466</td>
					<td>1385.3387</td>
				</tr>
				<tr>
					<td>CBlucy</td>
					<td>0.2529</td>
					<td>1863.7182</td>
				</tr>
			</table>

			<!-- Rays per Second Table -->
			<h2>Rays per Second</h2>
			<table>
				<tr>
					<th>Filenames</th>
					<th>Rendering w/ BVH (million rays/sec)</th>
					<th>Rendering w/out BVH (million rays/sec)</th>
				</tr>
				<tr>
					<td>Cow</td>
					<td>3.2244</td>
					<td>0.0170</td>
				</tr>
				<tr>
					<td>Building</td>
					<td>3.9930</td>
					<td>0.0022</td>
				</tr>
				<tr>
					<td>MaxPlanck</td>
					<td>2.0952</td>
					<td>0.0012</td>
				</tr>
				<tr>
					<td>Dragon</td>
					<td>1.9464</td>
					<td>0.0003</td>
				</tr>
				<tr>
					<td>CBlucy</td>
					<td>1.8980</td>
					<td>0.0003</td>
				</tr>
			</table>

			<!-- Tests per Ray Table -->
			<h2>Tests per Ray</h2>
			<table>
				<tr>
					<th>Filenames</th>
					<th>Intersection Checks w/ BVH</th>
					<th>Intersection Checks w/out BVH</th>
				</tr>
				<tr>
					<td>Cow</td>
					<td>3.565354</td>
					<td>5856.000000</td>
				</tr>
				<tr>
					<td>Building</td>
					<td>1.419775</td>
					<td>39506.000000</td>
				</tr>
				<tr>
					<td>MaxPlanck</td>
					<td>4.316633</td>
					<td>50801.000000</td>
				</tr>
				<tr>
					<td>Dragon</td>
					<td>3.493762</td>
					<td>105120.000000</td>
				</tr>
				<tr>
					<td>CBlucy</td>
					<td>3.574988</td>
					<td>133796.000000</td>
				</tr>
			</table>

			<p>The implementation of bounding volume hierarchies to the ray intersection rendering drastically impacts performance! For the simple cow model, the rendering was sped up 189.46 times, but with the Lucy statue rendering reached a staggering 7369.39 times acceleration! This pattern of increasing improvement is seen with ray/sec renders with of 189.67 and 6326.66 times acceleration respectively, which is slightly off due to data rounding. Most impressively, we can see the reason for the observed improvement by analyzing the intersection tests actually computed per ray, with the cow only testing 0.0609% and the lucy statue testing only 0.0027% of the total intersections the non-BVH algorithm tested. With short-circuiting, we have avoided having to test every primitive for every ray generated, only calculating a couple box intersections per ray to narrow it down to the handful of lead nodes and primitives for rendering! This cuts out naive intersection tests with primitives that would otherwise be obviously unlikely to hit all triangles and primitives in the mesh, thus the fraction of actual intersection tests, and cutting down compute time especially for complex models where BVH most effectively can eliminate nodes by entire sections proportionally. Notice how the tests per ray without BVH acceleration are equal to the number of primitives in the mesh, and that's for every ray!</p>

			<!--BVH Enabled: 3b0f77c9348af1fcdc680611e1d1fc7fa89efa71

	Cow:
	[PathTracer] Input scene file: ../../../dae/meshedit/cow.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0009 sec)
	[PathTracer] Building BVH from 5856 primitives... Done! (0.0035 sec)
	[PathTracer] Rendering... 100%! (0.1489s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 3.2244 million rays per second.
	[PathTracer] Averaged 3.565354 intersection tests per ray.
	[PathTracer] Saving to file: cow_screenshot_3-22_14-16-0.png... Done!

	Building:
	[PathTracer] Input scene file: ../../../dae/keenan/building.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0061 sec)
	[PathTracer] Building BVH from 39506 primitives... Done! (0.0167 sec)
	[PathTracer] Rendering... 100%! (0.1202s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 3.9930 million rays per second.
	[PathTracer] Averaged 1.419775 intersection tests per ray.
	[PathTracer] Saving to file: building_screenshot_3-22_12-52-51.png... Done!

	MaxPlanck:
	[PathTracer] Input scene file: ../../../dae/meshedit/maxplanck.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0071 sec)
	[PathTracer] Building BVH from 50801 primitives... Done! (0.0173 sec)
	[PathTracer] Rendering... 100%! (0.2291s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 2.0952 million rays per second.
	[PathTracer] Averaged 4.316633 intersection tests per ray.
	[PathTracer] Saving to file: maxplanck_screenshot_3-22_12-51-51.png... Done!

	Dragon:
	[PathTracer] Input scene file: ../../../dae/sky/dragon.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0186 sec)
	[PathTracer] Building BVH from 105120 primitives... Done! (0.0599 sec)
	[PathTracer] Rendering... 100%! (0.2466s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 1.9464 million rays per second.
	[PathTracer] Averaged 3.493762 intersection tests per ray.
	[PathTracer] Saving to file: dragon_screenshot_3-22_12-50-41.png... Done!

	CBlucy:
	[PathTracer] Input scene file: ../../../dae/sky/CBlucy.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0219 sec)
	[PathTracer] Building BVH from 133796 primitives... Done! (0.0580 sec)
	[PathTracer] Rendering... 100%! (0.2529s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 1.8980 million rays per second.
	[PathTracer] Averaged 3.574988 intersection tests per ray.
	[PathTracer] Saving to file: CBlucy_screenshot_3-22_12-52-29.png... Done!

	BVH disabled: ca1c237eb4f2bc995faf90da145848941e4259ea

	Cow:
	[PathTracer] Input scene file: ../../../dae/meshedit/cow.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0009 sec)
	[PathTracer] Building BVH from 5856 primitives... Done! (0.0001 sec)
	[PathTracer] Rendering... 100%! (28.2115s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 0.0170 million rays per second.
	[PathTracer] Averaged 5856.000000 intersection tests per ray.
	[PathTracer] Saving to file: cow_screenshot_3-22_14-15-5.png... Done!

	Building:
	[PathTracer] Input scene file: ../../../dae/keenan/building.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0054 sec)
	[PathTracer] Building BVH from 39506 primitives... Done! (0.0008 sec)
	[PathTracer] Rendering... 100%! (213.7916s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 0.0022 million rays per second.
	[PathTracer] Averaged 39506.000000 intersection tests per ray.
	[PathTracer] Saving to file: building_screenshot_3-22_12-58-20.png... Done!

	MaxPlanck:
	[PathTracer] Input scene file: ../../../dae/meshedit/maxplanck.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0074 sec)
	[PathTracer] Building BVH from 50801 primitives... Done! (0.0011 sec)
	[PathTracer] Rendering... 100%! (390.0616s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 0.0012 million rays per second.
	[PathTracer] Averaged 50801.000000 intersection tests per ray.
	[PathTracer] Saving to file: maxplanck_screenshot_3-22_13-9-52.png... Done!

	Dragon:
	[PathTracer] Input scene file: ../../../dae/sky/dragon.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0188 sec)
	[PathTracer] Building BVH from 105120 primitives... Done! (0.0026 sec)-->
			<!--[PathTracer] Rendering... 29%
	[PathTracer] Rendering canceled!-->
			<!--[PathTracer] Rendering... 100%! (1385.3387s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 0.0003 million rays per second.
	[PathTracer] Averaged 105120.000000 intersection tests per ray.
	[PathTracer] Saving to file: dragon_screenshot_3-22_13-41-13.png... Done!

	CBlucy:
	[PathTracer] Input scene file: ../../../dae/sky/CBlucy.dae
	[PathTracer] Rendering using 1 threads
	[PathTracer] Collecting primitives... Done! (0.0221 sec)
	[PathTracer] Building BVH from 133796 primitives... Done! (0.0033 sec)
	[PathTracer] Rendering... 100%! (1863.7182s)
	[PathTracer] BVH traced 480000 rays.
	[PathTracer] Average speed 0.0003 million rays per second.
	[PathTracer] Averaged 133796.000000 intersection tests per ray.
	[PathTracer] Saving to file: CBlucy_screenshot_3-22_14-13-36.png... Done!-->

			<h2>Part 3: Direct Illumination</h2>
			<p>Direct illumination complements zero bounce radiance.  Zero bounce radiance captures light that (as named) does not bounce off of any surfaces before hitting the camera. This is determined by the emissions from the intersected surface, which determines if it is a light source or not.</p>

			<p>With that implemented, one-bounce direct lighting appears in two forms. A brute-force random hemisphere sampling algorithm, and an iterative light source sampling algorithm.</p>

			<p>In the simpler former uniform hemisphere sampler, light rays are shot randomly in hopes of hitting a light source. This method takes a long time to converge due to low likelihoods for a surface ray to hit a light source (given that majority of the scene is not made of light sources). From a hit point, and for a standard number of samples, we sample a random light direction from the surface in object space. We generate a sample ray in world space by starting from the hit point, and converting our random light direction to world space. We avoid accidentally intersecting the surface we are bouncing from by starting intersection tests a miniscule amount of time after the ray is shot up. Using BVH acceleration from earlier, we see where the ray intersects the scene for light reflection estimation. We determine if the intersected inward surface has emissions (is a light); we calculate the outward bsdf reflectance of the surface that's being hit by the light; we account for the angle of attack affecting light reflectivity; and we divide this light contribution by a constant 1/(2*PI) in order to uniformly scale to the chance of sampling that ray. Direct accumulated lighting overall is then scaled down again by the number of samples taken per ray, and is used to light the render.</p>

			<p>Direct lighting by importance sampling light sources handles the two weaknesses of the hemisphere sampler:</p>
			<p>1. The chance of successfully random sampling a point lights source in a scene is neglibile</p>
			<p>2. Walls and objects won't contribute any one bounce illumination, so we're wasting samples that point at those non radiant surfaces. </p>
			<p>Instead, we make a few alterations to the sampling of the hemisphere algorithm to reduce computations. Instead of sampling a random direction, we iterate through all light sources (point or surfaces). For each, we sample an outward ray from the hit point all over the area of the light source, testing if any intersection occurs from just after the ray is shot to just before it would have hit the light. If no intersection occurs, we know there is nothing blocking a light ray from reaching the hit point, and thus we can similarly calculate the surface's' light reflection the same as before, but with the inward light's pdf now handled by the light sampler. Accumulated light contributions scale down by the area of the light source (or not at all for single light point sources) before being added to the total light estimation.</p>

			<p>Let's look at different renders using the hemisphere sampling with 1 and 64 sample rays, then with the importance light sampler with 1, 4, 16, and 64 ray samples.</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-20-13.png" width="400px" />
							<figcaption>Hemisphere - 1 sample.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-46-14.png" width="400px" />
							<figcaption>Hemisphere - 64 samples.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-20-27.png" width="400px" />
							<figcaption>Light - 1 sample.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-21-0.png" width="400px" />
							<figcaption>Light - 4 samples.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-21-21.png" width="400px" />
							<figcaption>Light - 16 samples.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="CBbunny_screenshot_3-24_1-21-34.png" width="400px" />
							<figcaption>Light - 64 samples.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Without any explanation, it is clear as day that the hemisphere sample method's results pale in comparison to the specific light sample method using the same parameters. The most discernable object is the light source, which is only visible since we included emission from the zero-bounce illumination underneath. Moving on to importance light sampling, even with only 1 ray sampled per light, the scene is accurately recreated. The bunny's ears, the shape of its face, the shadow it casts on the floor, and the colors of the inner walls are all processed. However, there is still some grain pixels on the floor that are still completely black, caused by the sampled ray choosing an unlucky direction, intersecting the bunny, when there are still areas of light that technically are unobstructed. Thus, we can mitigate this noise by increasing the ray sample count, spreading out the tested area over the light source's surface. The effects of this are even visible on the walls, where grain and texture in the low sample case are likely caused by varying angles of reflection, even if the bunny isn't posing a threat of blockage. At 64 samples, the walls successfully begin to reach their true smooth and gradiented state. Comparing both of the 64 sample ray renders, the darkness and noisiness of the hemisphere sampling reveals the necessity for significant minimum computation before a satisfactory lighting result (unshown) is possible. Overall, by going through each light in the environment, we can make more educated tests and reach a convincing render with a fraction of the time and effort.</p>

			<h2>Part 4: Global Illumination</h2>
			<p>Global illumination, the combination of both the direct (zero + one bounce) and indirect (multi-bounce) lighting, allows light to travel from non-light sources that reflect (diffused) light. From a high level, indirect lighting had to be added on top of our existing direct lighting from Part 3. We thus replace our one bounce function, for a new <b>at least</b> one bounce function. In the simple case where the maximum desired ray depth is one, we just return the original direct lighting. In the case where bounces are desired, aka ray depths are greater than one, we initialize the direct lighting and then call a recursive chain of consecutive bounces. We guaranteed that at least one bounce will occur with a specific if condition (when the inputted ray's depth matches the max desired ray bounces), but otherwise the code follows the russian roulette algorithm from lecture. We chose a termination chance value of 0.4 out of the range [0.3, 0.4] to make it more likely that high depth bounces are terminated. With this, we can input high-ceiling ray bounce inputs while expecting most of them to be pruned. This is important because ideally we would like to simulate infinite bounces, but light contributions get dimmer as they bounce, so having a decent chance random chance for any ray to short circuit drastically reduces the actual number of light rays that bounce "many" times. From our hit point, we sample a new ray, and if that ray wins a russian roulette roll, we calculate the light's contribution just as before, but normalized by the chance of winning the russian roulette. Each consecutive call is thus dimmer than the previous, until either termination or the max_ray_depth is reached. In short, each call get's its own idea of a one bounce (which gets scaled down) and adds any indirect lighting from the next surface hit to itself (which is later tallied all up into L_out).</p>

			<p>Let's take a look at some renders with global illumination! Numbers will represent the camera rays per pixel, max ray depth, and samples per area light respectively!</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="B2.1 CBdragon_microfacet_au.png" width="400px" />
							<figcaption>Globally illuminated dragon (no diffuse) - 1024,5,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B2.2 CBlucy.png" width="400px" />
							<figcaption>Globally illuminated lucy (no diffuse) - 1024,5,1.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<!--only direct vs only indirect scene-->
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="B3.1 CBbunny.png" width="400px" />
							<figcaption>Bunny with only <b>direct</b> lighting - 1024,1,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B3.2 CBbunny.png" width="400px" />
							<figcaption>Bunny with only <b>indirect</b> lighting - 1024,5,1.</figcaption>
						</td>
					</tr>
				</table>
			</div>
			<p>Notice in the direct lighting case, we see no reflected red or blue lighting around the room, and the shadow below the bunny is absolute. Only light with straight rays are rendered (plus zero bounce from the light to the camera). On the other hand, indirect lighting has no harsh lighting. The colors of the painted walls glaze their surroundings, and some light has even bounced around the bunny, illuminating areas that otherwise have no direct exposure to the ceiling light.</p>

			<!--render 0th to 5th bounce of light for CBbunny-->
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-0.png" width="400px" />
							<figcaption>Bunny of 0 bounce light, accumulating; 64,0,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-0.png" width="400px" />
							<figcaption>Bunny of 0 bounce light, mth; 64,0,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-1.png" width="400px" />
							<figcaption>Bunny of 1 bounce light, accumulating; 64,1,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-1.png" width="400px" />
							<figcaption>Bunny of 1 bounce light, mth; 64,1,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-2.png" width="400px" />
							<figcaption>Bunny of 2 bounce lights, accumulating; 64,2,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-2.png" width="400px" />
							<figcaption>Bunny of 2 bounce lights, mth; 64,2,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-3.png" width="400px" />
							<figcaption>Bunny of 3 bounce lights, accumulating; 64,3,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-3.png" width="400px" />
							<figcaption>Bunny of 3 bounce lights, mth; 64,3,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-4.png" width="400px" />
							<figcaption>Bunny of 4 bounce lights, accumulating; 64,4,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-4.png" width="400px" />
							<figcaption>Bunny of 4 bounce lights, mth; 64,4,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-5.png" width="400px" />
							<figcaption>Bunny of 5 bounce lights, accumulating; 64,5,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-5.png" width="400px" />
							<figcaption>Bunny of 5 bounce lights, mth; 64,5,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="BunnyAccum-100.png" width="400px" />
							<figcaption>Bunny of 100 bounce lights, accumulating; 64,100,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-100.png" width="400px" />
							<figcaption>Bunny of 100 bounce lights, mth; 64,100,1.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Taking a close look at the 2nd and 3rd bounce lights of mth unaccumulated light, we can clearly see that the 2nd bounce is decently bright. Not quite as bright as the direct lighting, as expected, but we see how the top of the bunny is darker than the bottom. We can imagine that this light just left the ceiling light, and is bouncing off the floor, causing this pattern. On the other hand, the 3rd bounce light gets dimmer still (as rays are further terminated and normalized), with no particular hot spot for light bounces. In the overall image, the second would be particularly important for spreading the brightest and strongest bottom floor light reflections, whereas the third is the brightest of the consecutive bounces that generally scatters light in the room. As the rays continue to bounce, they only continue to dim.</p>

			<p>Overall, the accumulated bunny renders reveal this. The image gets noticably brighter from the 2nd to 3rd bounce, but we only see diminishing returns as consecutive bounces are weaker and rarer. This would explain the negligible difference from the 5th to 100th max ray bounces. It is statistically improbable that a ray would reach 100 bounces (with our aforementioned termination probability of 40% per bounce). Instead we should look at the unaccumulated images to see the differences per stage. In the 0 and 1 bounce cases, no light has been accumulated so the images are decidedly the same. However, from the 2nd to 5th bounce, we can observe the surviving lights dim. By the 100th bounce, there are no remaining light bounces, with only the zero bounce ceiling lighting visible.</p>

			<p>Below we include some similar bunnies with the samples per pixel increased to 1024, which will follow the same trends.</p>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="BunnyNoAccum-0.png" width="400px" />
							<figcaption>Bunny of 0 bounce light, accumulating; 1024,0,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B5.3 CBbunny.png" width="400px" />
							<figcaption>Bunny of 1 bounce light, accumulating; 1024,1,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="B5.4 CBbunny.png" width="400px" />
							<figcaption>Bunny of 2 bounce light, accumulating; 1024,2,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B5.5 CBbunny.png" width="400px" />
							<figcaption>Bunny of 3 bounce light, accumulating; 1024,3,1.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="B5.6 CBbunny.png" width="400px" />
							<figcaption>Bunny of 4 bounce lights, accumulating; 1024,4,1.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B5.1 CBbunny.png" width="400px" />
							<figcaption>Bunny of 100 bounce lights, accumulating; 1024,100,1.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>After increasing the samples per pixel to 1024, the bunny of 100 max rays has minimal noise or grain pixels. However, the same underlying diminishing returns from increased max_ray_count remains.</p>

			<!--2nd and 3rd bounce for CBbunny-->

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="B6.1 CBbunny.png" width="400px" />
							<figcaption>Bunny of 1 pixel sample, accumulating; 1,5,4.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B6.2 CBbunny.png" width="400px" />
							<figcaption>Bunny of 2 pixel samples, accumulating; 2,5,4.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="B6.3 CBbunny.png" width="400px" />
							<figcaption>Bunny of 4 pixel samples, accumulating; 4,5,4.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B6.4 CBbunny.png" width="400px" />
							<figcaption>Bunny of 8 pixel samples, accumulating; 8,5,4.</figcaption>
						</td>
					</tr>
					<tr>
						<td style="text-align: center;">
							<img src="B6.5 CBbunny.png" width="400px" />
							<figcaption>Bunny of 16 pixel samples, accumulating; 16,5,4.</figcaption>
						</td>
						<td style="text-align: center;">
							<img src="B6.6 CBbunny.png" width="400px" />
							<figcaption>Bunny of 64 pixel samples, accumulating; 64,5,4.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td style="text-align: center;">
							<img src="B6.7 CBbunny.png" width="400px" />
							<figcaption>Bunny of 1024 pixel samples, accumulating; 1024,5,4.</figcaption>
						</td>
					</tr>
				</table>
			</div>

			<p>Finally, we can inspect the affect of sample-per-pixel rates. Noise and speckles make the 1 sample render appear like a vintage film photo. Only by incrementing the sample rate do these grains get averaged out, as light is bounced and diffused more evenly across the scene. By 64, the image has lost the most damning noise, with the worst parts visible in dark/shadowy sections such as the underside of the bunny or the corners of the walls. Then with 1024 the noise is all but handled.</p>

			<h2>Part 5: Adaptive Sampling</h2>
			Adaptive Sampling a method of sampling where instead of trying to use equal and a possibly high number of samples per pixel, we instead sample more on the difficult areas of the image so that the less important parts of our image render faster, and the most important part of our image has more details since we reduce a large amount of noise. Adaptive sampling works since some pixels converge faster with a lower sampling rate while some others need more sampling to blend and take care of random noise.

			Our implementation of adaptive sampling keeps track of s1 and s2 which are our sum and sum of squares of illuminance, by keep track of these it makes our computations for mean, variance, and standard deviation easier. We go through every iteration of num_samples which acts as the amount of batches and in each we loop through samplesPerBatch times, in each we sample and create a ray, with this ray, we grab it's illuminance and add that to s1, and the square of the illuminance to s2 and add the illuminance to our total_radiance then increment counter to keep looping through our samples. At the end of every batch, we calculate the mean, varaince, and std deviation with s1 and s2, then we have I which we use to measure a pixel's convergence, when our our I which is defined as (1.96 * std/sqrt(n)) is less than or equal our set maxTolerance*mean, then we say that the pixel has converged and that we are able to stop tracing rays for this pixel, otherwise we continuing the loop. We do this for each of the batches and at the end, we update our sampleBuffer's pixel with the mean total_radiance and add the amount of batches to our sampleCountBuffer.

			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="spheres_rendering.png.png" width="480px" height="360px" />
						<figcaption>Spheres</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_rendering_rate.png.png" width="480px" height="360px" />
						<figcaption>Spheres Sampling Rates</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="wall-e.png.png" width="480px" height="360px" />
						<figcaption>Wall-E</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="wall-e_rate.png.png" width="480px" height="360px" />
						<figcaption>Wall-E Sampling Rates</figcaption>
					</td>
				</tr>
			</table>
			<p>What made this homework the most different from the previous ones was the freedom of options for ways to render. Relying on our local machines to do rendering without GPU acceleration was also a major consideration for how our workflow changed. Not only that, but working during Spring Break while no one else was around also made the work feel more isolated than before. It was critical to communicate what we were working on and clarify questions we had as they came up to determine how we should allocate work. There's been a lot of time invested in this homework specifically, but we are proud of what was achieved.</p>
		</div>
	</body>
</html>